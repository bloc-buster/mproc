MPROC (multiprocessing version of CCC)
CCC written by Sharlee Climer (climer@mail.umsl.edu)
multiprocessing version written by James Smith (jjs3k2@umsystem.edu)

requirements:
	g++ compiler
	make
	Linux
	SLURM
	overwrite mproc.sh and ccc.sh with sbatch parameters relevant to your system

required files:
	main.cpp (invokes main.sh)
	main.sh (invokes ccc.sh, mproc, or ccc)
	mproc.sh
	mproc.cpp
	helper.cpp
	ccc.sh (invokes ccc)
	bloc.cpp
	sem.h
	shmem.h
	timer.h
	params.h
	bloc.h
	checksum.txt (generated programmatically)
	data.key (generated programmatically)
	Makefile

project structure:
	The project is stored in the resources folder. We require that all output be stored outside of the resources folder. 
	The output file is automatcially placed in the same folder as the input file, and the output folder containing log files will be placed in that folder as well. Any attempt to read from or write to the folder containing the executables will result in an error.

project structure:
	project folder (name of your choice)
		resources (folder)
			all required executable files are stored here
		INSTRUCTIONS (text file)

configure:
	overwrite mproc.sh and ccc.sh with appropriate sbatch parameters, then comment out the warning and the exit statement
		the program will not run until you comment out the warning and the exit statement
	bloc.h has been set for SNPs as rows
	if you need SNPs as columns, change setting in bloc.h

compile (from within resources folder):
	srun make clean
	srun make
	(on each run, main.sh recompiles several files since it must rewrite params.h)

run:
	the program requires two runs
		on the first run, the program generates partial files in the output folder
		on the second run, the program gathers the partial files into a complete file
	first, run main with srun main or just ./main
		main has required parameters
		main then invokes main.sh
		main.sh then invokes sbatch on mproc.sh
		mproc.sh then invokes mproc with srun
		the .sh files generate no new .sh files...instead, a single .sh file is reused with varying parameters
	wait for all jobs to complete
	then, run main with -z and no parameters
	read the SLURM output file for the most recent job to verify the checksum
		if comparisons equals expected comparisons then the results are correct

different runs at same time:
	not possible - you must wait until each batch completes before starting another run
	after the first batch completes, you must perform the second run with ./main -z
	the -z option will read the params.h file containing the starting input parameters
	if you run main.cpp again on new files before running main -z on the first files, the params.h variables will be overwritten
	hence, you must run the program on one batch of files at a time
	a large file should not take much longer than an hour so waiting on each run should not take long

usage:
	(prepare files)
	./main input.txt output.gml threshold numInd numSNPs numHeaderRows numHeaderCols granularity1 (default 1) granularity2 (default 7) max_simultaneous_processes (default 15) temp_output_folder (default ../temp_output_files) semaphores (default 0) 
		explanation - the temp_output_folder is not for the output.gml file, it's a temporary folder that gets erased after the -z option
	(combine files)
	./main -z
		explanation - program does not know when all jobs have finished...after all jobs complete, tell program to join partial files from output folder into a gml file
		-z - if the first run had two granularity values

explanation:
	input - a snps data file containing snp data
	output - name for the output file, the file is autogenerated, any file with same name will be overwritten
	threshold - decimal between 0 and 1
	numInd - number of individuals in the input file
	numSNPs - number of snps in the input file
	numHeaderRows - number of header rows at top of input file
	numheaderCols - number of non-data columns at front of each row
	(the rest of the parameters have defaults and may be left blank)
	granularity1 - integer between 1 and 7 for number of divisions into start table made by main.sh
	granularity2 - integer between 1 and 7 for number of divisions into those divisions made by each run of ccc
		- optionally 0...the program will not run multiprocessing, instead just splitting the file into partitions and launching a separate SLURM job on each
	max_simultaneous_processes - the number of processors found in each node on your HPC system (no more than 24), or the maximum processes at a time allowed on your system
	temp_output_files - a temporary folder, not for the output.gml file, small partial files are written to the output folder, the folder is autogenerated, any folder with same name will be removed
	semaphores - either 0 or 1, default 0, if 1 the program will reduce the number of output files by having multiple processes write to the same file which will be locked with semaphores, if 0 the program will let each process write to a separate file which will create up to 1000 small files in the temp output folder

output files:
	.gml file with results, do not put in the temp output folder
	temp_output_files (erasable folder containing partial gml files)
	SLURM output files

example run:
	./main /home/username/data/acgt.txt /home/username/data/out.gml 0.7 10 1000 1 11 1 7 15 /home/username/data/temp_output_files
	(wait until all jobs have completed, then generate gml file)
	./main -z

checking results:
	after invoking -z, read the resulting SLURM output file
	if the expected comparisons don't equal the comparisons, then the resulting gml file is wrong
	your selected granularity values may not have been a good fit for the input file size
	run the entire program again with lower granularity values

troubleshooting:
	if the program ever throws an error, check if it forgot to release memory or semaphores
	type
	ipcs
	then, if your username shows up in the list, memory or semaphores were not released
	so, find the id that appears next to your username
	if your name appeared in the memory section, type
	ipcrm -m #
	where # = id
	if your name appeared in the semaphore section, type
	ipcrm -s #
	where # = id
	then, type ipcs again to make sure it was released

disclaimer:
	We are not responsible for any damages resulting from use of the product. Email one of the authors if you have questions.

