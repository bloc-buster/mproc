CCC (multiprocessing version)
CCC written by Sharlee Climer (climer@mail.umsl.edu)
multiprocessing version written by James Smith (jjs3k2@umsystem.edu)

requirements:
	g++ compiler
	make
	Linux
	SLURM
	overwrite ccc.sh with sbatch parameters relevant to your system

required files:
	ccc
	helper
	batch
	batch.cpp (invokes batch.sh)
	batch.sh (invokes ccc.sh or ccc)
	ccc.sh (invokes ccc)
	bloc.cpp
	helper.cpp
	sem.h
	shmem.h
	timer.h
	params.h
	bloc.h
	checksum.txt (generated programmatically)
	data.key (generated programmatically)
	Makefile

configure:
	overwrite ccc.sh with appropriate sbatch parameters, then comment out the warning and the exit statement
		the program will not run until you comment out the warning and the exit statement
	bloc.h has been set for SNPs as rows
		if you need SNPs as columns, change setting in bloc.h

compile:
	srun make clean
	srun make
	(on each run, batch.sh recompiles since it must rewrite params.h)

run:
	the program requires two runs
		on the first run, the program generates partial files in the output folder
		on the second run, the program gathers the partial files into a complete file
	first, run batch with srun batch or just ./batch
		batch has required parameters
		batch then invokes batch.sh
		batch.sh then invokes sbatch on ccc.sh
		ccc.sh then invokes ccc with srun
		the .sh files generate no new .sh files...instead, a single .sh file is reused with varying parameters
	wait for all jobs to complete
	then, run batch with -z and no parameters, or four parameters if you launched multiple jobs
		four parameters are required for multiple jobs or else they will overwrite each others' configurations
	read the SLURM output file for the most recent job to verify the checksum
		if comparisons equals expected comparisons then the results are correct, otherwise they may be wrong

different runs at same time:
	not recommended - a large file should not take much longer than an hour so waiting on each run should not take long
	however, if you want to run multiple instances at the same time, follow these instructions
	do not use the default output folder, you must have different output file names and different output folder names
	do not launch another job until the first job has started running
	do not use the -z option...instead, specify four parameters
	even if all of these instructions are followed, if multiple runs are scheduled on the same node, their semaphores might overlap, resulting in miscomputed checksum

usage:
	(prepare files)
	./batch input.txt output.gml threshold numInd numSNPs numHeaderRows numHeaderCols granularity1 (default 1) granularity2 (default 7) max_simultaneous_processes (default 15) output_folder (default temp_output_files) semaphores (default 0) 
		explanation - the outputfolder is not for the output.gml file, it's a temporary folder that gets erased after the -z or four parameter option
	(combine files)
	./batch -z (or -c)
		explanation - program does not know when all jobs have finished...after all jobs complete, tell program to join partial files from output folder into a gml file
		-z - if the first run had two granularity values
		-c - if the first run had just one granularity value and the second was zero
	(or, for multiple simultaneous runs)
	./batch outputfolder outputfile num_ind num_snps
		explanation - the -z option reads the params.h file, but if you launch multiple jobs they overwrite that file so instead you must tell it the parameters

explanation:
	input - a snps data file containing snp data
	output - name for the output file, the file is autogenerated, any file with same name will be overwritten
	threshold - decimal between 0 and 1
	numInd - number of individuals in the input file
	numSNPs - number of snps in the input file
	numHeaderRows - number of header rows at top of input file
	numheaderCols - number of non-data columns at front of each row
	(the rest of the parameters have defaults and may be left blank)
	granularity1 - integer between 1 and 7 for number of divisions into start table made by batch.sh
	granularity2 - integer between 1 and 7 for number of divisions into those divisions made by each run of ccc
		- optionally 0...the program will not run multiprocessing, instead just splitting the file into partitions and launching a separate SLURM job on each
	max_simultaneous_processes - the number of processors found in each node on your HPC system (no more than 24), or the maximum processes at a time allowed on your system
	output_folder - a temporary folder, not for the output.gml file, small partial files are written to the output folder, the folder is autogenerated, any folder with same name will be removed
	semaphores - either 0 or 1, default 0, if 1 the program will reduce the number of output files by having multiple processes write to the same file which will be locked with semaphores, if 0 the program will let each process write to a separate file which will create up to 1000 small files in the temp output folder

output files:
	.gml file with results, do not put in the output folder
	temp_output_files (erasable folder containing partial gml files)
	SLURM output files

example run:
	./batch acgt.txt data/out.gml 0.7 10 1000 1 11 1 7 15 data/temp_output_files
	(wait until all jobs have completed, then generate gml file)
	./batch -z

multiple simultaneous runs:
	./batch file1.txt data/out1.gml 0.7 100 1000 1 11 1 7 15 data/temp_output_files1
	(wait until job 1 starts running)
	./batch file2.txt data/out2.gml 0.7 100 1000 1 11 1 7 15 data/temp_output_files2
	(wait until job 1 has completed)
	./batch data/temp_output_files1 data/out1.gml 100 1000
	(wait until job 2 has completed)
	./batch data/temp_output_files2 data/out2.gml 100 1000

checking results:
	after invoking -z, or the four parameter option, read the resulting SLURM output file
	if the expected comparisons don't equal the comparisons, then the resulting gml file is wrong
	your selected granularity values may not have been a good fit for the input file size
	run the entire program again with different granularity values

troubleshooting:
	if the program ever throws an error, check if it forgot to release memory or semaphores
	type
	ipcs
	then, if your username shows up in the list, memory or semaphores were not released
	so, find the id that appears next to your username
	if your name appeared in the memory section, type
	ipcrm -m #
	where # = id
	if your name appeared in the semaphore section, type
	ipcrm -s #
	where # = id
	then, type ipcs again to make sure it was released

disclaimer:
	We are not responsible for any damages resulting from use of the product. Email one of the authors if you have questions.

